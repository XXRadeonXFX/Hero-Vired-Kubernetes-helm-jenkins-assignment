pipeline {
  agent any
  environment {
    DOCKER_CREDS_ID = 'DOCKER-PRINCE-CRED'
    AWS_CREDS_ID    = 'PRINCE-AWS-CRED'
    BACKEND_IMAGE   = "xxradeonxfs/learner-backend:latest"
    FRONTEND_IMAGE  = "xxradeonxfs/learner-frontend:latest"
    CLUSTER_NAME    = "prince-eks"
    REGION          = "ap-south-1"
    KUBECONFIG      = "/var/lib/jenkins/.kube/config"
  }
  
  stages {
    stage('Checkout Code') {
      steps {
        checkout scm
      }
    }
    
    stage('Configure AWS CLI for EKS') {
      steps {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
          sh '''
            mkdir -p $(dirname "$KUBECONFIG")
            export KUBECONFIG=$KUBECONFIG
            aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
            
            # Get account ID for context
            ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
            
            # Set the context
            kubectl config use-context arn:aws:eks:$REGION:$ACCOUNT_ID:cluster/$CLUSTER_NAME
            
            # Verify connection
            kubectl get nodes
            
            # Verify authentication
            kubectl auth can-i get pods --namespace=default || echo "Warning: Limited permissions"
          '''
        }
      }
    }
    
    stage('Build & Push Backend Image') {
      steps {
        dir('learnerReportCS_backend') {
          withCredentials([usernamePassword(credentialsId: "${DOCKER_CREDS_ID}", usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
            sh '''
              docker build -t $BACKEND_IMAGE .
              echo "$PASSWORD" | docker login -u "$USERNAME" --password-stdin
              docker push $BACKEND_IMAGE
            '''
          }
        }
      }
    }
    
    stage('Build & Push Frontend Image') {
      steps {
        dir('learnerReportCS_frontend') {
          withCredentials([usernamePassword(credentialsId: "${DOCKER_CREDS_ID}", usernameVariable: 'USERNAME', passwordVariable: 'PASSWORD')]) {
            sh '''
              docker build -t $FRONTEND_IMAGE .
              echo "$PASSWORD" | docker login -u "$USERNAME" --password-stdin
              docker push $FRONTEND_IMAGE
            '''
          }
        }
      }
    }
    
    stage('Deploy MongoDB') {
      steps {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
          dir('mongodb') {
            sh '''
              # Re-export environment variables and refresh kubeconfig
              export KUBECONFIG=$KUBECONFIG
              export AWS_DEFAULT_REGION=$REGION
              
              # Refresh the kubeconfig to ensure we have valid credentials
              aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
              
              # Get account ID and set context
              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              kubectl config use-context arn:aws:eks:$REGION:$ACCOUNT_ID:cluster/$CLUSTER_NAME
              
              # Verify we can connect
              echo "Checking cluster connection..."
              kubectl cluster-info
              
              # Create namespace if it doesn't exist
              echo "Creating/checking database namespace..."
              kubectl get namespace database || kubectl create namespace database
              
              # Check if MongoDB is already running
              echo "Checking if MongoDB is already deployed..."
              if kubectl get deployment mongodb -n database >/dev/null 2>&1; then
                echo "âœ… MongoDB deployment already exists and running. Skipping MongoDB deployment."
                kubectl get pods -n database -l app=mongodb
              else
                echo "ðŸ“¦ MongoDB not found. Deploying MongoDB..."
                # Apply MongoDB deployments
                kubectl apply -f mongodb-deployment.yaml -n database
                kubectl apply -f mongodb-service.yaml -n database
                
                # Wait for MongoDB to be ready
                echo "â³ Waiting for MongoDB to be ready..."
                kubectl wait --for=condition=available --timeout=300s deployment/mongodb -n database
              fi
              
              # Verify deployment
              echo "ðŸ” Verifying MongoDB deployment..."
              kubectl get pods -n database
              kubectl get services -n database
            '''
          }
        }
      }
    }
    
    stage('Check and Clean Existing Application Deployments') {
      steps {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
          sh '''
            # Re-export environment variables and refresh kubeconfig
            export KUBECONFIG=$KUBECONFIG
            export AWS_DEFAULT_REGION=$REGION
            
            # Refresh the kubeconfig
            aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
            
            # Get account ID and set context
            ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
            kubectl config use-context arn:aws:eks:$REGION:$ACCOUNT_ID:cluster/$CLUSTER_NAME
            
            echo "ðŸ” Checking for existing application deployments..."
            
            # Check for existing Helm releases
            echo "ðŸ“‹ Checking for existing Helm releases..."
            EXISTING_RELEASES=$(helm list -n default -q 2>/dev/null || echo "")
            
            if [ ! -z "$EXISTING_RELEASES" ]; then
              echo "Found existing Helm releases: $EXISTING_RELEASES"
              for release in $EXISTING_RELEASES; do
                if [ "$release" != "mongodb" ] && [ "$release" != "mongo" ]; then
                  echo "ðŸ—‘ï¸  Uninstalling existing release: $release"
                  helm uninstall $release -n default --wait --timeout=5m || echo "Failed to uninstall $release"
                else
                  echo "âš ï¸  Skipping MongoDB-related release: $release"
                fi
              done
            else
              echo "âœ… No existing Helm releases found."
            fi
            
            # Check for standalone deployments (not managed by Helm)
            echo "ðŸ“‹ Checking for standalone deployments..."
            BACKEND_EXISTS=$(kubectl get deployment learner-backend -n default >/dev/null 2>&1 && echo "true" || echo "false")
            FRONTEND_EXISTS=$(kubectl get deployment learner-frontend -n default >/dev/null 2>&1 && echo "true" || echo "false")
            
            if [ "$BACKEND_EXISTS" = "true" ]; then
              echo "ðŸ—‘ï¸  Found existing backend deployment. Removing..."
              kubectl delete deployment learner-backend -n default --wait=true --timeout=300s || echo "Failed to delete backend deployment"
              kubectl delete service learner-backend-service -n default --wait=true --timeout=60s || echo "Backend service not found or failed to delete"
            fi
            
            if [ "$FRONTEND_EXISTS" = "true" ]; then
              echo "ðŸ—‘ï¸  Found existing frontend deployment. Removing..."
              kubectl delete deployment learner-frontend -n default --wait=true --timeout=300s || echo "Failed to delete frontend deployment"
              kubectl delete service learner-frontend-service -n default --wait=true --timeout=60s || echo "Frontend service not found or failed to delete"
            fi
            
            # Wait for complete cleanup
            echo "â³ Waiting for complete cleanup..."
            sleep 15
            
            # Verify cleanup
            echo "ðŸ” Verifying cleanup..."
            kubectl get deployments -n default | grep learner || echo "âœ… No learner deployments found - cleanup successful!"
            kubectl get services -n default | grep learner || echo "âœ… No learner services found - cleanup successful!"
            
            echo "âœ… Cleanup phase completed!"
          '''
        }
      }
    }
    
    stage('Deploy to EKS via Helm') {
      steps {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
          dir('helm/mern-chart') {
            sh '''
              # Re-export environment variables and refresh kubeconfig
              export KUBECONFIG=$KUBECONFIG
              export AWS_DEFAULT_REGION=$REGION
              
              # Refresh the kubeconfig
              aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
              
              # Get account ID and set context
              ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
              kubectl config use-context arn:aws:eks:$REGION:$ACCOUNT_ID:cluster/$CLUSTER_NAME
              
              # Verify Helm is available
              echo "ðŸ”§ Checking Helm installation..."
              which helm || echo "Helm not found in PATH"
              helm version
              
              # Validate Helm chart
              echo "âœ… Validating Helm chart..."
              helm lint .
              
              # Show what will be deployed
              echo "ðŸ“‹ Helm template preview:"
              helm template learner-app . \\
                --set backend.image=$BACKEND_IMAGE \\
                --set frontend.image=$FRONTEND_IMAGE
              
              # Deploy with Helm
              echo "ðŸš€ Deploying application with Helm..."
              helm upgrade --install learner-app . \\
                --namespace default \\
                --wait \\
                --timeout=10m \\
                --set backend.image=$BACKEND_IMAGE \\
                --set frontend.image=$FRONTEND_IMAGE \\
                --atomic \\
                --debug
              
              # Verify deployment
              echo "ðŸ” Verifying deployment..."
              kubectl get pods -n default
              kubectl get services -n default
              
              # Show deployment status
              echo "ðŸ“Š Deployment status:"
              kubectl rollout status deployment/learner-backend -n default --timeout=300s
              kubectl rollout status deployment/learner-frontend -n default --timeout=300s
              
              # Show Helm release status
              echo "ðŸ“ˆ Helm release status:"
              helm status learner-app -n default
              
              # Show final state
              echo "ðŸŽ¯ Final deployment state:"
              kubectl get all -n default -l app.kubernetes.io/managed-by=Helm
            '''
          }
        }
      }
    }
  }
  
  post {
    success {
      echo "âœ… Deployment successful!"
      script {
        withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
          sh '''
            export KUBECONFIG=$KUBECONFIG
            aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
            
            echo "=== ðŸŽ‰ Deployment Summary ==="
            echo "ðŸ“¦ MongoDB Pods (Database Namespace):"
            kubectl get pods -n database
            echo ""
            echo "ðŸš€ Application Pods (Default Namespace):"
            kubectl get pods -n default
            echo ""
            echo "ðŸŒ Services:"
            kubectl get services -n default
            kubectl get services -n database
            echo ""
            echo "ðŸ“¡ LoadBalancer External IP (Frontend):"
            EXTERNAL_IP=$(kubectl get service learner-frontend-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
            if [ ! -z "$EXTERNAL_IP" ]; then
              echo "Frontend URL: http://$EXTERNAL_IP"
            else
              echo "External IP pending... Check again in a few minutes with:"
              echo "kubectl get service learner-frontend-service -n default"
            fi
            echo ""
            echo "ðŸ“Š Helm Releases:"
            helm list -n default
          '''
        }
      }
    }
    failure {
      echo "âŒ Pipeline failed. Check the logs."
      script {
        try {
          withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', credentialsId: "${AWS_CREDS_ID}"]]) {
            sh '''
              export KUBECONFIG=$KUBECONFIG
              aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
              
              echo "=== ðŸš¨ Debug Information ==="
              kubectl cluster-info || echo "Cannot connect to cluster"
              kubectl get nodes || echo "Cannot get nodes"
              kubectl config current-context || echo "No current context"
              
              echo "=== ðŸ“‹ Failed Pods Information ==="
              echo "Default namespace pods:"
              kubectl get pods -n default || echo "Cannot get default namespace pods"
              echo "Database namespace pods:"
              kubectl get pods -n database || echo "Cannot get database namespace pods"
              
              echo "=== ðŸ“‹ Pod Descriptions (for failed pods) ==="
              for pod in $(kubectl get pods -n default --field-selector=status.phase=Failed -o name 2>/dev/null); do
                echo "Describing $pod:"
                kubectl describe $pod -n default
              done
              
              echo "=== ðŸ“‹ Recent Events ==="
              kubectl get events --sort-by=.metadata.creationTimestamp -n default | tail -20 || echo "Cannot get events"
              
              echo "=== ðŸ“‹ Helm Releases Status ==="
              helm list -n default || echo "Cannot get helm releases"
            '''
          }
        } catch (Exception e) {
          echo "Failed to get debug information: ${e.getMessage()}"
        }
      }
    }
    always {
      // Clean up docker images to save space
      sh '''
        echo "ðŸ§¹ Cleaning up Docker resources..."
        docker system prune -f || true
      '''
    }
  }
}
